%
% GNU courseware, XIN YUAN, 2017
%

\section{人工神经网络}

\frame{
\centerline{\textbf{\Huge{人工神经网络}}}
}

\frame{\frametitle{定义}

人工神经网络是由大量处理单元互联组成的非线性、自适应信息处理系统。
}

\frame{\frametitle{思想}

在现代神经科学研究成果的基础上提出，试图通过模拟大脑神经网络处理、记忆信息的方式进行信息处理。

~

非线性、非局限性、非定常性、非凸性。

~

自适应、自组织、自学习。
}

\frame{\frametitle{思想}
人工智能的三大流派：

	\begin{itemize}
		\item 符号主义
		\item 联结主义
		\item 行为主义
	\end{itemize}
}

\frame{\frametitle{思想}

基于逻辑符号和规则推理的专家系统，在处理直觉、非结构化信息方面有缺陷。

~

人工神经网络是连接主义的观点，是神经元相互联接而成的自适应非线性动态系统，
分为前向网络(有向无环图)和反馈网络(无向完备图)两类。

~

理论研究：MP模型、Hebb规则、感知器、适应谐振ART理论、自组织映射、认知机网络、非线性动力学。
}

\frame{\frametitle{思想}
	\begin{itemize}
		\item<1-> 万能逼近理论、高维空间中的低维流形、类比分段函数、
映射到高维特征空间(重新部署点以便获得线性处理或其他性质良好的处理)、
高阶到低阶的局部调制。
		\item<2-> 泛化问题：欠拟合，过拟合，正则的作用，VC维模型复杂度理论，
训练集和验证集的复杂度-误差-方差曲线
		\item<3-> 凸优化与非凸优化：加凸集约束的正则项(模型复杂程度的单调增函数，几何解释)；
梯度消失，梯度爆炸，自动微分
		\item<4-> 对抗网络的本质，边界的确定，与正则的关系，与传输方程的关系。
	\end{itemize}
}

\frame{\frametitle{种类}
	\begin{itemize}
		\item<1-> Hopfield
		\item<2-> 波尔兹曼机(模拟退火及MCMC)
		\item<3-> 联想记忆
		\item<4-> BP
		\item<5-> 极限学习机(ELM)
		\item<6-> 局部逼近神经网络(CMAC,RBF,B样条)
	\end{itemize}
}

\frame{\frametitle{种类}
	\begin{itemize}
		\item<1-> 自组织SOM
		\item<2-> ART
		\item<3-> SVM(描述模型复杂度的VC维，核方法，升维)
		\item<4-> 强化学习(行为主义，可分层，多智能体，可类比自动控制)
		\item<5-> 降维处理(主成分分析，低秩，补全问题)
	\end{itemize}
}

\frame{\frametitle{种类}
	\begin{itemize}
		\item<1-> 集成式网络(boosting，梯度推进机，决策树，随机森林，知识图谱)
		\item<2-> 量子神经网络
		\item<3-> 脉冲耦合
		\item<4-> 混沌神经网络
		\item<5-> 深度学习(卷积、循环、递归，置信网络，生成式对抗网络，编解码器，迁移学习，教师学生，蒸馏，
端到端，注意力，预训练，扩散模型，对比学习，增量学习，果蝇的大脑)
	\end{itemize}
}

\frame{\frametitle{种类}
	\begin{itemize}
		\item<1-> 图神经网络
		\item<2-> 隐私保护学习(联邦学习，差分隐私学习，联合学习，分离学习)
		\item<3-> 因果学习(关联、干预、反事实估计和推断，结构因果，因果强化，去相关，深度稳定学习、方差分析)
		\item<4-> 大语言模型
	\end{itemize}
}

\frame{\frametitle{深度学习}
深度学习的科普

~

参见\href{https://ishare.ifeng.com/c/s/v002JgwF4NYcbmQ82S4-_eS-_3--f5R3EL7B4JxV5Rtmq7LCNA__}{网页}
}

\frame{\frametitle{随机优化}
针对的是使用梯度下降法求解最优化目标泛函的问题。
其中的训练样本数据都是最优化目标泛函中的常数。
具体研究的是训练样本数量过大的情形下梯度的计算问题。

~

从一个初始的点(代表一个函数的参数)出发在函数空间中搜索最优化目标函数的解。
每次迭代都只选用部分样本数据或者重新采样来估计当前的各种梯度来更新解，
以减少计算量。
}

\frame{\frametitle{随机优化}
\begin{itemize}
	\item<1-> 零阶估计(用函数值和一些假设算梯度和二阶海森矩阵)
	\item<2-> 方差缩减(每次样本采样，梯度值不一样，要看成随机变量，方差大，结合先前迭代步信息缩减)
	\item<3-> 二阶稳定点(二阶海森矩阵，抑制收敛到局部最大点，局部鞍点)
	\item<4-> 动量(每次再多走一点距离，加快收敛)
	\item<5-> 朗之万动力学(随机噪声)
\end{itemize}
}

\frame{\frametitle{随机优化}
\begin{itemize}
	\item<1-> 假设依然较多，为了证明收敛，更多是在凑数字的游戏。适用场景存疑。
	\item<2-> 每次迭代的对当前点的修改量，或者求下一个点，都要求解一个当前点周边范围内的最优化子问题。
	\item<3-> 依然无法避免收敛到局部最小点。
\end{itemize}
}

\frame{\frametitle{阅读}
	\begin{itemize}
		\item<1-> 反思。参见\href{https://mp.weixin.qq.com/s/hdBGdOGcwxDt8mfCjj4mQQ}{网页}
		\item<2-> 现状。参见\href{https://mp.weixin.qq.com/s/2YC1N3MB8G7mw1HThucceQ}{网页}
		\item<3-> 工业案例。参见\href{https://mp.weixin.qq.com/s/YTI5QxNjVIq2PJeOKxbc8g}{网页}
		\item<4-> 其他落地案例：非关键、消费级，如电子商务推荐等。
	\end{itemize}
}

%end
